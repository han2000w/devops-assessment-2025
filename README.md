**a. 클라우드 아키텍처 다이어그램**
<img width="986" height="697" alt="image" src="https://yogiting.s3.ap-northeast-2.amazonaws.com/%EA%B5%AC%EC%84%B1%EB%8F%84.png" />

**b. 기술 선택 및 설계 근거**
- 멀티 AZ를 기본 VPC 설계 전략으로 선정하여 하나의 AZ 다운시에도 서비스가 지속될수 있도록 하였습니다.
- DB와 Redis가 고가용성을 가질수 있게 멀티 AZ 환경에 생성하였습니다.
- 보안을 위해 EKS,DB,Redis등 중요 시스템은 Private 서브넷에 배치하여 외부 접근을 제한하였고 허용된 인원만 Public 서브넷의 Bastion(JumpBox)서버를 통해 Private Subnet에 접근 하도록 설계 하였습니다.
- ELB에 WAF를 연결하여 SQL Injection, XSS등 웹공격을 차단해 L7(애플리케이션 계층) 보안을 강화 하였습니다.
- AWS의 관리형 Kubernetes인 EKS를 운영환경의 인프라 플랫폼으로 선택했습니다. AWS는 타 CSP사 대비하여 높은 클라우드 점유율을 가지고 있으며 이로인해 운영환경에서의 검증이 충분히 이루어졌고, 양질의 기술가이드와 참고 가능한 외부 레퍼런스 자료가 많아서 안정적인 시스템 운영에 도움이 될 요소가 많습니다.
- EKS를 선택한 주요한 이유는 안정적인 시스템 운영과 확장성을 고려하여 선택했습니다.
  - K8s의 Master Node와 Worker Node는 클러스터링이 되어있어 어느 한곳의 노드가 다운 되어도 서비스 지속성을 가지고 있고 k8s의 최소 실행 단위인 Pod또한 단일 Pod로 서비스를 하는게 아닌 다수의 Pod로 서비스를 제공 할 수 있기때문에 고가용성과 부하 분산을 통해 안정적으로 리퀘스트에 대응 가능합니다.
    그리고 Pod가 시스템 오류등으로 Error 상태에 진입하게 되면 자동으로 문제가 있는 Pod를 폐기하고 정상적인 Pod를 다시 생성하는 셀프힐링 기능을 통해 인프라 담당자의 개입없이도 서비스를 정상화 할 수 있다는 장점이 있습니다.
  - 또한 평소에는 사용량이 적었다가 특정 시간에 트래픽이 몰리는 시스템에 대해서도 Pod의 수평확장 기능인 HPA를 사용하여 시스템 다운 없이 트래픽에 대응 할 수 있으며, 평소에 최소한의 리소스로 서비스를 운영하다가 필요한 시점에만 인프라를 증설 하기 때문에 비용적인 면에서도 합리적입니다.
  - 서비스의 신규 버전 배포시에 신규버전에 에러가 발생하는 상황에서 간단히 이전 버전의 ReplicaSet으로 롤백이 가능하여 신속한 장애 대응이 가능합니다.
  - Nginx Ingress 컨트롤러, 오토스케일링 도구인 Kapenter등 다양한 Cloud Native 환경에서 제공되는 오픈소스 도구를 사용하여 시스템을 안정적이고 효율적으로 운영 가능하게 합니다.
 - CI/CD는 Github Action과 ArgoCD를 선정하였습니다. Github Action은 Github을 소스 저장소로 사용하는 환경에서 손쉽게 통합하여 사용할수 있는 장점이 있고 각종 테스트나 이슈관리들을 별도의 외부 툴을 설치 하지 않고도 Github에서 통합하여 사용할수 있는 장점이 있습니다.
   ArgoCD는 대표적인 쿠버네티스의 CD툴로서 가볍고 직관적인 UI가 제공되며 UI에서 서비스 배포, 롤백, 로그확인등을 가능하게 합니다. 특히 신규 배포를 위해 Github Action이나 Jenkins등 CI툴에 제공해야 했던 k8s클러스터 접근 권한을 주지 않아도 되어 보안을 한층 강화 할 수 있습니다.
 - DB 접속 정보, 외부 API 키 등 민감한 정보는 소스 코드나 GitHub에 노출되지 않도록 Vault를 활용 하도록 설계했습니다. Vault에 저장된 시크릿을 사용하기 위해서 Vault서버로의 API 호출이나 k8s Secret으로 생성후 시크릿 마운트를 하는 방법을 통해 안전하게 시크릿을 저장하고 사용할 수 있습니다.
    
**c. 운영 자동화 및 장애 대응 계획**
- **모니터링 전략**:
  - 노드의 CPU와 Memory 사용량이 임계치 도달시 Slack 알림(70% warning, 90% critical)
  - 서비스의 Error rate가 5분동안 5%시 warning 알림, 5분동안 10%시 critical 알림
  - RPS, p50/p90/p99 latency를 모니터링하여 속도 저하시 Slack 알림  
- **무중단 배포 전략**:
  - 기본적인 배포 전략으로 Rolling update를 사용하며 k8s의 graceful shutdown과 readiness probe 기능을 사용하여 세션 끊킴없는 안전한 배포 전략 사용
  - 신규 버전의 기능 안정성을 실제 사용자로부터 테스트 할 필요가 있을시 Istio를 구성하여 Canary 배포를 사용
- **장애 대응 시나리오**:
  - DB 연결 실패 시: app의 메트릭, 모니터링 대시보드, 에러 로그, slack알림등을 확인하여 어떤 문제가 있는지 빠르게 먼저 에러에 대해 확인을 합니다. DB연결 실패에 대한 주요 원인은 커넥션풀 부족, AWS 가용영역 장애, 비밀번호 불일치등으로
    발생 할수 있습니다.
    - App의 커넥션풀 부족시 pod를 추가 생성하여 빠르게 커넥션풀을 확보하거나, 리소스 가용량을 고려해 App의 커넥션풀을 증설시키고 서비스를 재배포 합니다.
    - AWS 가용영역 장애에 대비하여 RDS 생성시 다중AZ 옵션을 선택하여 특정 AZ다운시 자동으로 Fail-over가 될수 있도록 합니다.
    - RDS 생성시 AWS Secret manager를 통해 암호를 관리하게 되면 주기적으로 비밀번호를 자동 변경하게 됩니다. 이로인해 접속 비밀번호 불일치로 DB연결이 실패하게 됩니다. 만약 해당 기능을 사용한다면 주기적인 모니터링/확인 및
      External Secret이나 Vault를 활용해서 자동으로 변경된 비밀번호를 sync 하도록 설정합니다.
  - 특정 API 서버 장애 시
    - 특정 pod의 커넥션풀 고갈 oom등으로 인해 서비스 불능시 Istio의 circuit breaker기능을 사용하여 문제 있는 pod로의 호출을 차단하고 복구가 되면 다시 호출을 허용합니다.
    - 전체 pod의 API장애시에는 빠르게 이전 버전으로 롤백을 하여 서비스를 안정화 시키고, 에러의 문제점을 파악하여 해결한 후 다시 재배포를 진행합니다.
  - 트래픽 급증 시
    - 트래픽 급증시의 대응은 빠르고 효율적인 오토스케일링을 제공하는 k8s의 최대 장점입니다. HPA를 통해 pod를 수평확장 하고, Karpenter나 CA를 활용해 워커 노드를 확장하여 급증하는 트래픽에 대응 할 수 있습니다.
    - 만약 유입되는 트래픽이 정상적인 호출이 아닌 악의적인 목적을 가진 공격성 트래픽이라면 AWS의 보안그룹과 WAF의 보안정책을 활용하여 악의적인 트래픽 유입을 차단 할 수 있습니다.


